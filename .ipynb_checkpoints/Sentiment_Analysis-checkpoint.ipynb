{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis (Trump vs Clinton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "import stopwords as st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the file 'tweetering.py' and store the contents (tweets) in a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening to '#trump' and 'trump' ...\n"
     ]
    }
   ],
   "source": [
    "%run tweetering.py trump 250     #save about 250 tweets containing \"trump\" or \"#trump\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening to '#clinton' and 'clinton' ...\n"
     ]
    }
   ],
   "source": [
    "%run tweetering.py clinton 250       #save about 250 tweets containing \"clinton\" or \"#clinton\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to clean a tweet; remove the usernames, urls, numbers etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processTweet(tweet):\n",
    "    \n",
    "    if tweet.startswith(\"RT\"):\n",
    "        i = tweet.index(':')\n",
    "        tweet = tweet[i+2:]\n",
    "    \n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','',tweet)\n",
    "    tweet = re.sub('([0-9]+)','', tweet)\n",
    "    tweet = re.sub('@[^\\s]+','',tweet)\n",
    "    tweet = re.sub('[\\s]+', ' ', tweet)\n",
    "    tweet = re.sub('&amp;', '', tweet)\n",
    "    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)\n",
    "    tweet = tweet.strip('\\'\"')\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A list containing top most words which don't count towards sentiment analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stoplist = [\"clinton\",\"trump\",\"hillary\",\"donald\",'chair',\"rt\",\":\",\"oh\",\"clinton.\",\"trump,\",\"team\",\".\",\"bill\",\"like\",\"made\",\"now\",\"trump:\",\"via\",\"\\xe2\\x80\\x94\",\"de\",\"\\xe2\\x80\\x93\",\"republican\",\"will\",\"going\",\"-\",\"campaign\",\"election\",\"us\",\"things]\",\"president\",\n",
    "            \"camp\",\"seen\",\"--\",\"well\",\"breaking:\",\"tv\",\"november\",\"media\",\"anonymous\",\"video\",\"ng\",\"can\",\"just\",\"girl\",\"calls\",\"ready\",\"trump\\'s\",\"clinton\\'s\",\"saying\",\"really\",\"girl\",\"calls\",\"former\",\"electing\",\"teen\",\n",
    "           \"say\",\"presidential\",\"%\",\"obama\",\"new\",\"take\",\"talk\",\"vote\",\"people\",\"may\",\"watch\",\"test\",\"voters:\",\"must\",\"gop\",\"live\",\"breaks\",\n",
    "           \"poll\",\"yay\",\"one\",\"trumpâ€™s\",\"voting\",\"nothing\",\"trump.\",\"real\",\"old\",\"back\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to read the tweets from the file and convert it into a dictionary of words having their frequency as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def countinfile(filename):\n",
    "    d = {}\n",
    "    stopwords = st.get_stopwords(\"en\") + stoplist\n",
    "    with open(filename, \"r\") as fp:\n",
    "        for line in fp:\n",
    "            line = processTweet(line)\n",
    "            #print line\n",
    "            words = line.strip().split()\n",
    "            for word in words:\n",
    "                try:\n",
    "                    if(word not in stopwords):\n",
    "                        d[word] += 1\n",
    "                except KeyError:\n",
    "                    d[word] = 1\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NeerajB\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\ipykernel\\__main__.py:11: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
     ]
    }
   ],
   "source": [
    "dict_clinton = countinfile(\"clinton.txt\")\n",
    "dict_trump = countinfile(\"trump.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting the 10 most associated words and storing them in a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump:\n",
      "         Word  Frequency\n",
      "0       women          7\n",
      "1      sexist          6\n",
      "2  challenges          4\n",
      "3        drug          4\n",
      "4         win          3\n",
      "5        help          3\n",
      "6       white          3\n",
      "7      women:          3\n",
      "8       woman          2\n",
      "9     support          2\n",
      "\n",
      "Clinton:\n",
      "            Word  Frequency\n",
      "0         emails         13\n",
      "1     foundation         12\n",
      "2  podestaemails         10\n",
      "3      wikileaks          9\n",
      "4   neverhillary          6\n",
      "5        cocaine          6\n",
      "6     corruption          6\n",
      "7         muslim          6\n",
      "8          email          6\n",
      "9          china          5\n"
     ]
    }
   ],
   "source": [
    "data1 = Counter(dict_trump).most_common(10)\n",
    "data2 = Counter(dict_clinton).most_common(10)\n",
    "\n",
    "df_trump = pd.DataFrame(data1, columns=[\"Word\",\"Frequency\"])\n",
    "df_clinton = pd.DataFrame(data2, columns=[\"Word\",\"Frequency\"])\n",
    "\n",
    "print \"Trump:\"\n",
    "print df_trump\n",
    "print \"\\nClinton:\"\n",
    "print df_clinton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning positive or negative sentiments to the words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump:\n",
      "         Word  Frequency  Sentiment\n",
      "0       women          7         -1\n",
      "1      sexist          6         -1\n",
      "2  challenges          4          1\n",
      "3        drug          4         -1\n",
      "4         win          3          1\n",
      "5        help          3          1\n",
      "6       white          3         -1\n",
      "7      women:          3         -1\n",
      "8       woman          2         -1\n",
      "9     support          2          1\n",
      "\n",
      "Clinton:\n",
      "            Word  Frequency  Sentiment\n",
      "0         emails         13         -1\n",
      "1     foundation         12          1\n",
      "2  podestaemails         10         -1\n",
      "3      wikileaks          9         -1\n",
      "4   neverhillary          6         -1\n",
      "5        cocaine          6         -1\n",
      "6     corruption          6         -1\n",
      "7         muslim          6          1\n",
      "8          email          6         -1\n",
      "9          china          5          1\n"
     ]
    }
   ],
   "source": [
    "df_trump[\"Sentiment\"] = [-1,-1,1,-1,1,1,-1,-1,-1,1]\n",
    "df_clinton[\"Sentiment\"] = [-1,1,-1,-1,-1,-1,-1,1,-1,1]\n",
    "\n",
    "print \"Trump:\"\n",
    "print df_trump\n",
    "print \"\\nClinton:\"\n",
    "print df_clinton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the average sentiment value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump's average sentiment: -1.3\n",
      "Clinton's average sentiment: -3.3\n"
     ]
    }
   ],
   "source": [
    "sum1 = 0\n",
    "for i in range(len(df_trump)):\n",
    "    sum1 += df_trump[\"Frequency\"][i] * df_trump[\"Sentiment\"][i]\n",
    "print \"Trump's average sentiment: \" + str(float(sum1) / 10)\n",
    "\n",
    "sum2 = 0\n",
    "for i in range(len(df_clinton)):\n",
    "    sum2 += df_clinton[\"Frequency\"][i] * df_clinton[\"Sentiment\"][i]\n",
    "print \"Clinton's average sentiment: \" + str(float(sum2) / 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seems that there are more chances of Donald Trump to win over Hillary Clinton according to the worldwide tweets on Oct 14, 2016."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
